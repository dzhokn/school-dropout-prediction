{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Preprocess the data\n",
    "\n",
    "Let's first load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the float formatter for numpy arrays\n",
    "float_formatter = \"{:.4f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1 Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename: str) -> list[list[str]]:\n",
    "    \"\"\"Load the data from the csv file.\"\"\"\n",
    "    csv = []\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            csv.append(row)\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2 Drop the first row (table headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4423\n"
     ]
    }
   ],
   "source": [
    "# Remove the first row (feature names)\n",
    "csv = load_csv('data/students_dataset.csv')\n",
    "data = csv[1:]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3 Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(data: list[list[str]]):\n",
    "    '''Loop through the data and encode the categorical variables'''\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        row[-1] = 0 if row[-1] == 'Dropout' else 1 if row[-1] == 'Graduate' else 2 # 2 Enrolled\n",
    "        new_data.append(row)\n",
    "    return new_data\n",
    "\n",
    "# Encode the 'Target' column (0 - Dropout, 1 - Graduate, 2 - Enrolled)\n",
    "data = encode_categorical_variables(data)   #data_stripped TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.4 Remove noise\n",
    "\n",
    "The students with status `Enrolled` are kind of a noise for our model, since these are students who haven't graduated yet (have some hanging exams, I guess) and yet, these students are not formally stated as `Dropouts` either. So, their final status is actually blurry and unclear. Hence, we remove them from the training dataset, so they don't confuse our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3629, 37)\n"
     ]
    }
   ],
   "source": [
    "# Remove the enrolled students (keep only Dropout and Graduate)\n",
    "data_filtered = [row for row in data if row[-1] != 2]\n",
    "\n",
    "# Parse the csv strings to float numbers\n",
    "data_filtered = np.array(data_filtered, dtype=np.float32)\n",
    "\n",
    "print(data_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.5 Remove outliers\n",
    "Some more noise purge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_iqr(data: list[list[float]], col_idx: int, k: float) -> list[list[float]]:\n",
    "    '''Remove the outliers from the data'''\n",
    "    column_data = [row[col_idx] for row in data]\n",
    "\n",
    "    Q1 = np.percentile(column_data, 25)\n",
    "    Q3 = np.percentile(column_data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - k * IQR\n",
    "    upper_bound = Q3 + k * IQR\n",
    "    \n",
    "    return [row for row in data if row[col_idx] >= lower_bound and row[col_idx] <= upper_bound] # Return the rows that within range\n",
    "\n",
    "# Remove outliers\n",
    "for col_idx in range(len(data_filtered[0]) - 1): # Skip the last column (Target)\n",
    "    data_filtered = remove_outliers_iqr(data_filtered, col_idx, 1.1)  # We could afford to be more aggressive here, since we have enough data.\n",
    "\n",
    "print(len(data_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000 1.0313 0.6736 1.3192 0.0000 0.0000 -0.9975 0.0000 1.3052 0.9723\n",
      " -0.4016 -1.3962 -0.6743 0.7057 0.0000 0.0000 0.0000 -0.5589 -0.9147\n",
      " 0.9747 0.0000 0.0000 -0.2589 0.3688 0.2765 0.4356 0.0000 0.0000 -0.2904\n",
      " 1.5581 -0.9684 -0.4986 0.0000 -0.8862 -1.5391 -1.5891 1.0000]\n"
     ]
    }
   ],
   "source": [
    "def scale_data(X: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"Standardize features by removing the mean and scaling to unit variance.\"\"\"\n",
    "    epsilon = 1e-8  # Small constant to prevent division by zero\n",
    "    return (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + epsilon)\n",
    "\n",
    "# Transform the data (every column value to be in short range between -2 and 2)\n",
    "data_without_target = [row[:-1] for row in data_filtered] # Do not scale the target column   \n",
    "data_filtered_scaled = scale_data(data_without_target)\n",
    "data_filtered_scaled = [np.hstack((row, [data_filtered[i][-1]])) for i, row in enumerate(data_filtered_scaled)]  # Add the target column back\n",
    "\n",
    "# Convert the list of arrays to a numpy array\n",
    "data_filtered_scaled = np.array(data_filtered_scaled)\n",
    "\n",
    "print(data_filtered_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Split the data\n",
    "Let's randomize and split the data into two chunks:\n",
    "* `train_set` - usually, this is around 67-90% of all the data\n",
    "* `test_set` - usually, a smaller subset which purpose is only to test the model accuracy after it's been trained\n",
    "\n",
    "In our case for best results we would utilize **80% of all the data** to train the model and 20% for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584, 37) (147, 37)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(X: np.ndarray, test_size: float):\n",
    "    '''Split the data into training and testing sets'''\n",
    "    # Shuffle the data\n",
    "    X = X[np.random.permutation(len(X))]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = X[:int(len(X) * (1 - test_size))]\n",
    "    X_test = X[int(len(X) * (1 - test_size)):]\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(data_filtered_scaled, test_size=0.20)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Develop an Autoencoder\n",
    "\n",
    "Now we need to build an **Autoencoder neural network**. Basically, it's a **backpropagation** network with 3 layers, where the input and output layers have **same sizes** and the hidden middle layer has smaller size (compressed representation).\n",
    "\n",
    "The other change is that in autoencoder model the final loss is measured as a diff between the **original input** ($x$) and the **reconstructed output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X: np.ndarray):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def sigmoid_derivative(X: np.ndarray):\n",
    "    return X * (1 - X)\n",
    "\n",
    "class SimpleAutoencoder:\n",
    "    def __init__(self, input_size: int, hidden_size: int, learning_rate: float):\n",
    "        # Initialize random weights with Xavier/Glorot initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "        self.W2 = np.random.randn(hidden_size, input_size) * np.sqrt(2.0 / hidden_size)\n",
    "        self.b1 = np.zeros(hidden_size)\n",
    "        self.b2 = np.zeros(input_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Encoder\n",
    "        self.hidden = sigmoid(np.dot(X, self.W1) + self.b1)\n",
    "        # Decoder\n",
    "        self.output = sigmoid(np.dot(self.hidden, self.W2) + self.b2)\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, X: np.ndarray):\n",
    "        # Calculate gradients\n",
    "        output_error = self.output - X\n",
    "        output_delta = output_error * sigmoid_derivative(self.output)\n",
    "\n",
    "        hidden_error = np.dot(output_delta, self.W2.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.W2 -= self.learning_rate * np.dot(self.hidden.T, output_delta)\n",
    "        self.b2 -= self.learning_rate * np.sum(output_delta)\n",
    "        \n",
    "        self.W1 -= self.learning_rate * np.dot(X.T, hidden_delta)\n",
    "        self.b1 -= self.learning_rate * np.sum(hidden_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Instantiate the autoencoder\n",
    "\n",
    "Now, we have to instatiate the model and train it with the prepared data. In regard to the `hidden_layer_size` I experimented with different numbers - from $1$ to $15$. And from $10$ up to $13$ the results were the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(X: np.ndarray, autoencoder: SimpleAutoencoder, epochs: int):\n",
    "    '''Train the autoencoder and return the reconstruction loss for each epoch'''\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the data\n",
    "        X = X[np.random.permutation(len(X))]\n",
    "\n",
    "        # Forward pass\n",
    "        output = autoencoder.forward(X)\n",
    "        \n",
    "        # Calculate loss (MSE)\n",
    "        loss = np.mean(np.square(output - X))\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Backward pass\n",
    "        autoencoder.backward(X)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate was determined after zillions of executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train autoencoder\n",
    "input_size = len(X_train[0])  # All features (including the target)\n",
    "hidden_size = 12  # Compressed representation\n",
    "autoencoder = SimpleAutoencoder(input_size, hidden_size, learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Measure the prediction accuracy\n",
    "\n",
    "#### How to evaluate a reconstruction\n",
    "Now, we will use the model to reconstruct the data for all rows in our `test_set`. Then, we will compare the **Target** value between the original and reconstructed datasets.\n",
    "\n",
    "NB: We consider a student a dropout prediction if the model produced a Target value between $0.50$ and $1.00$. All lower values are considered $0$ (not a dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reconstructions(input: np.ndarray, autoencoder: SimpleAutoencoder, is_anomaly: bool = False) -> float:\n",
    "    '''Compare the original data to the reconstructed data'''\n",
    "    # Get reconstructions for the test set\n",
    "    reconstructions = autoencoder.forward(input)\n",
    "\n",
    "    # Extract the predicted target column and make it 0, if the value is below 0.5. Otherwise, round it up to 1\n",
    "    reconstructed_targets = reconstructions[:, -1]\n",
    "    reconstructed_targets = np.where(reconstructed_targets < 0.50, 0, 1)\n",
    "\n",
    "    # Compare the original target to the reconstructed predictions\n",
    "    correct_predictions = sum(reconstructed_targets == input[:, -1])\n",
    "\n",
    "    # Calculate the accuracy in percentage\n",
    "    return correct_predictions / len(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### How to measure model performance\n",
    "\n",
    "We need to create a function that measures model performance. It could be measured in two ways:\n",
    "* reconstruction accuracy\n",
    "We simply forward the test set through the trained neural network and compare the reconstructured values to the original ones. We expect the accuracy here to be high (i.e. the reconstruction loss to be low).\n",
    "\n",
    "* anomaly detection accuracy\n",
    "But more importantly, we need to track the anomaly detection capabilites of our model. For that purpose, we take the train set and purposefully skew the `Target` value (from $0$ to $1$ and vice versa). This way we produce a clear set of anomaly data points.\n",
    "\n",
    "Then we get the anomaly dataset through the autoencoder and compare the results (reconstruction vs original). The expectation here is to have very low prediction accuracy (i.e. if the anomaly says the student is `Graduate`, our model is expected to predict the student would `Dropout`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dropout_prediction_accuracy(X_test: np.ndarray, autoencoder: SimpleAutoencoder) -> float:\n",
    "    '''Check the accuracy of the reconstructed targets'''\n",
    "\n",
    "    # Separate the test set into regular and anomaly data\n",
    "    regulars = X_test.copy()\n",
    "    anomalies = X_test.copy()\n",
    "\n",
    "    # Reverse all target values in the anomaly dataset (e.g. create anomalies)\n",
    "    anomalies[:, -1] = 1 - anomalies[:, -1] # 0 -> 1 and 1 -> 0\n",
    "\n",
    "    # Get reconstructions for the test set\n",
    "    regular_reconstruction_accuracy = compare_reconstructions(regulars, autoencoder) # We expect this to be high\n",
    "    anomaly_reconstruction_accuracy = compare_reconstructions(anomalies, autoencoder, True) # We expect this to be low\n",
    "    anomaly_detection_accuracy = 1 - anomaly_reconstruction_accuracy\n",
    "\n",
    "    print(f\"Regular reconstruction accuracy: {regular_reconstruction_accuracy:.2%}\")\n",
    "    print(f\"Anomaly detection accuracy: {anomaly_detection_accuracy:.2%}\")\n",
    "\n",
    "    return anomaly_detection_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Train the model\n",
    "\n",
    "Now, let's train the model. Since there are variations in the output performance (mostly between 90% and 95%), we run several attempts until we achieve a good enough metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 on 731 rows\n",
      "Regular reconstruction accuracy: 91.84%\n",
      "Anomaly detection accuracy: 91.84%\n",
      "Attempt #2 on 731 rows\n",
      "Regular reconstruction accuracy: 93.88%\n",
      "Anomaly detection accuracy: 93.20%\n"
     ]
    }
   ],
   "source": [
    "attempt = 0\n",
    "# Run the trainings until we get a good enough model (93-97%)\n",
    "while True:\n",
    "    attempt += 1\n",
    "    print(f\"Attempt #{attempt} on {len(data_filtered_scaled)} rows\")\n",
    "    # Shuffle and split the data into training and testing sets (NB: This is important! It turns out the accuracy depends on which part of the dataset is being used for training)\n",
    "    X_train, X_test = train_test_split(data_filtered_scaled, test_size=0.20)\n",
    "\n",
    "    # Instantiate the autoencoder\n",
    "    autoencoder = SimpleAutoencoder(input_size, hidden_size, learning_rate=0.003)\n",
    "\n",
    "    # Train the model\n",
    "    losses = train_autoencoder(X_train, autoencoder, epochs=10000)\n",
    "\n",
    "    # Test accuracy\n",
    "    anomaly_detection_accuracy = check_dropout_prediction_accuracy(X_test, autoencoder)\n",
    "\n",
    "    if anomaly_detection_accuracy > 0.93:\n",
    "        break # The accuracy is good enough. Stop the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

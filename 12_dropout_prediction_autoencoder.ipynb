{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Preprocess the data\n",
    "\n",
    "Let's first load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the float formatter for numpy arrays\n",
    "float_formatter = \"{:.4f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1 Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename: str) -> list[list[str]]:\n",
    "    \"\"\"Load the data from the csv file.\"\"\"\n",
    "    csv = []\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            csv.append(row)\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2 Drop the first row (table headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4423\n"
     ]
    }
   ],
   "source": [
    "# Remove the first row (feature names)\n",
    "csv = load_csv('data/students_dataset.csv')\n",
    "data = csv[1:]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3 Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(data: list[list[str]]):\n",
    "    '''Loop through the data and encode the categorical variables'''\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        row[-1] = 0 if row[-1] == 'Dropout' else 1 if row[-1] == 'Graduate' else 2 # 2 Enrolled\n",
    "        new_data.append(row)\n",
    "    return new_data\n",
    "\n",
    "# Encode the 'Target' column (0 - Dropout, 1 - Graduate, 2 - Enrolled)\n",
    "data = encode_categorical_variables(data)   #data_stripped TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.4 Remove noise\n",
    "\n",
    "The students with status `Enrolled` are kind of a noise for our model, since these are students who haven't graduated yet (have some hanging exams, I guess) and yet, these students are not formally stated as `Dropouts` either. So, their final status is actually blurry and unclear. Hence, we remove them from the training dataset, so they don't confuse our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3629, 37)\n"
     ]
    }
   ],
   "source": [
    "# Remove the enrolled students (keep only Dropout and Graduate)\n",
    "data_filtered = [row for row in data if row[-1] != 2]\n",
    "\n",
    "# Parse the csv strings to float numbers\n",
    "data_filtered = np.array(data_filtered, dtype=np.float32)\n",
    "\n",
    "print(data_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.5 Remove outliers\n",
    "Some more noise purge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_iqr(data: list[list[float]], col_idx: int, k: float) -> list[list[float]]:\n",
    "    '''Remove the outliers from the data'''\n",
    "    column_data = [row[col_idx] for row in data]\n",
    "\n",
    "    Q1 = np.percentile(column_data, 25)\n",
    "    Q3 = np.percentile(column_data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - k * IQR\n",
    "    upper_bound = Q3 + k * IQR\n",
    "    \n",
    "    return [row for row in data if row[col_idx] >= lower_bound and row[col_idx] <= upper_bound] # Return the rows that within range\n",
    "\n",
    "# Remove outliers\n",
    "for col_idx in range(len(data_filtered[0]) - 1): # Skip the last column (Target)\n",
    "    data_filtered = remove_outliers_iqr(data_filtered, col_idx, 1.1)  # We could afford to be more aggressive here, since we have enough data.\n",
    "\n",
    "print(len(data_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000 1.0313 0.6736 1.3192 0.0000 0.0000 -0.9975 0.0000 1.3052 0.9723\n",
      " -0.4016 -1.3962 -0.6743 0.7057 0.0000 0.0000 0.0000 -0.5589 -0.9147\n",
      " 0.9747 0.0000 0.0000 -0.2589 0.3688 0.2765 0.4356 0.0000 0.0000 -0.2904\n",
      " 1.5581 -0.9684 -0.4986 0.0000 -0.8862 -1.5391 -1.5891 1.0000]\n"
     ]
    }
   ],
   "source": [
    "def scale_data(X: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"Standardize features by removing the mean and scaling to unit variance.\"\"\"\n",
    "    epsilon = 1e-8  # Small constant to prevent division by zero\n",
    "    return (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + epsilon)\n",
    "\n",
    "# Transform the data (every column value to be in short range between -2 and 2)\n",
    "data_without_target = [row[:-1] for row in data_filtered] # Do not scale the target column   \n",
    "data_filtered_scaled = scale_data(data_without_target)\n",
    "data_filtered_scaled = [np.hstack((row, [data_filtered[i][-1]])) for i, row in enumerate(data_filtered_scaled)]  # Add the target column back\n",
    "\n",
    "# Convert the list of arrays to a numpy array\n",
    "data_filtered_scaled = np.array(data_filtered_scaled)\n",
    "\n",
    "print(data_filtered_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Split the data\n",
    "Let's randomize and split the data into two chunks:\n",
    "* `train_set` - usually, this is around 67-90% of all the data\n",
    "* `test_set` - usually, a smaller subset which purpose is only to test the model accuracy after it's been trained\n",
    "\n",
    "In our case for best results we would utilize **80% of all the data** to train the model and 20% for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584, 37) (147, 37)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(X: np.ndarray, test_size: float):\n",
    "    '''Split the data into training and testing sets'''\n",
    "    # Shuffle the data\n",
    "    X = X[np.random.permutation(len(X))]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train = X[:int(len(X) * (1 - test_size))]\n",
    "    X_test = X[int(len(X) * (1 - test_size)):]\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(data_filtered_scaled, test_size=0.20)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Develop an Autoencoder\n",
    "\n",
    "Now we need to build an **Autoencoder neural network**. Basically, it's a **backpropagation** network with 3 layers, where the input and output layers have **same sizes** and the hidden middle layer has smaller size (compressed representation).\n",
    "\n",
    "The other change is that in autoencoder model the final loss is measured as a diff between the **original input** ($x$) and the **reconstructed output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X: np.ndarray):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def sigmoid_derivative(X: np.ndarray):\n",
    "    return X * (1 - X)\n",
    "\n",
    "class SimpleAutoencoder:\n",
    "    def __init__(self, input_size: int, hidden_size: int, learning_rate: float):\n",
    "        # Initialize random weights with Xavier/Glorot initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "        self.W2 = np.random.randn(hidden_size, input_size) * np.sqrt(2.0 / hidden_size)\n",
    "        self.b1 = np.zeros(hidden_size)\n",
    "        self.b2 = np.zeros(input_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Encoder\n",
    "        self.hidden = sigmoid(np.dot(X, self.W1) + self.b1)\n",
    "        # Decoder\n",
    "        self.output = sigmoid(np.dot(self.hidden, self.W2) + self.b2)\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, X: np.ndarray):\n",
    "        # Calculate gradients\n",
    "        output_error = self.output - X\n",
    "        output_delta = output_error * sigmoid_derivative(self.output)\n",
    "\n",
    "        hidden_error = np.dot(output_delta, self.W2.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.W2 -= self.learning_rate * np.dot(self.hidden.T, output_delta)\n",
    "        self.b2 -= self.learning_rate * np.sum(output_delta)\n",
    "        \n",
    "        self.W1 -= self.learning_rate * np.dot(X.T, hidden_delta)\n",
    "        self.b1 -= self.learning_rate * np.sum(hidden_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Instantiate the autoencoder\n",
    "\n",
    "Now, we have to instatiate the model and train it with the prepared data. In regard to the `hidden_layer_size` I experimented with different numbers - from $1$ to $15$. And from $10$ up to $13$ the results were the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(X: np.ndarray, autoencoder: SimpleAutoencoder, epochs: int):\n",
    "    '''Train the autoencoder and return the reconstruction loss for each epoch'''\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the data\n",
    "        X = X[np.random.permutation(len(X))]\n",
    "\n",
    "        # Forward pass\n",
    "        output = autoencoder.forward(X)\n",
    "        \n",
    "        # Calculate loss (MSE)\n",
    "        loss = np.mean(np.square(output - X))\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Backward pass\n",
    "        autoencoder.backward(X)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate was determined after zillions of executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train autoencoder\n",
    "input_size = len(X_train[0])  # All features (including the target)\n",
    "hidden_size = 12  # Compressed representation\n",
    "autoencoder = SimpleAutoencoder(input_size, hidden_size, learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Measure the prediction accuracy\n",
    "\n",
    "Now, we will use the model to reconstruct the data for all rows in our `test_set`. Then, we will compare the **Target** value between the original and reconstructed datasets.\n",
    "\n",
    "NB: We consider a student a dropout prediction if the model produced a Target value between $0.50$ and $1.00$. All lower values are considered $0$ (not a dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dropout_prediction_accuracy(X_test: np.ndarray, autoencoder: SimpleAutoencoder) -> float:\n",
    "    '''Check the accuracy of the reconstructed targets'''\n",
    "\n",
    "    # Separate the test set into regular and anomaly data\n",
    "    regulars = X_test.copy()\n",
    "    anomalies = X_test.copy()\n",
    "\n",
    "    # Reverse all target values in the anomaly dataset (e.g. create anomalies)\n",
    "    anomalies[:, -1] = 1 - anomalies[:, -1] # 0 -> 1 and 1 -> 0\n",
    "\n",
    "    # Get reconstructions for the test set\n",
    "    regular_reconstruction_accuracy = compare_reconstructions(regulars, autoencoder) # We expect this to be high\n",
    "    anomaly_reconstruction_accuracy = compare_reconstructions(anomalies, autoencoder, True) # We expect this to be low\n",
    "    anomaly_detection_accuracy = 1 - anomaly_reconstruction_accuracy\n",
    "\n",
    "    print(f\"Regular reconstruction accuracy: {regular_reconstruction_accuracy:.2%}\")\n",
    "    print(f\"Anomaly detection accuracy: {anomaly_detection_accuracy:.2%}\")\n",
    "\n",
    "    return anomaly_detection_accuracy\n",
    "\n",
    "def compare_reconstructions(input: np.ndarray, autoencoder: SimpleAutoencoder, is_anomaly: bool = False) -> float:\n",
    "    '''Compare the original data to the reconstructed data'''\n",
    "    # Get reconstructions for the test set\n",
    "    reconstructions = autoencoder.forward(input)\n",
    "\n",
    "    # Extract the predicted target column and make it 0, if the value is below 0.5. Otherwise, round it up to 1\n",
    "    reconstructed_targets = reconstructions[:, -1]\n",
    "    reconstructed_targets = np.where(reconstructed_targets < 0.50, 0, 1)\n",
    "\n",
    "    # Compare the original target to the reconstructed predictions\n",
    "    correct_predictions = sum(reconstructed_targets == input[:, -1])\n",
    "\n",
    "    # Calculate the accuracy in percentage\n",
    "    return correct_predictions / len(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the model against our test set, which is **absolutely unknown** for the model and is **4x times bigger** than the set we used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 on 731 rows\n",
      "Regular reconstruction accuracy: 91.16%\n",
      "Anomaly detection accuracy: 90.48%\n",
      "Attempt #2 on 731 rows\n",
      "Regular reconstruction accuracy: 94.56%\n",
      "Anomaly detection accuracy: 94.56%\n"
     ]
    }
   ],
   "source": [
    "attempt = 0\n",
    "# Run the trainings until we get a good enough model (93-97%)\n",
    "while True:\n",
    "    attempt += 1\n",
    "    print(f\"Attempt #{attempt} on {len(data_filtered_scaled)} rows\")\n",
    "    # Shuffle and split the data into training and testing sets (NB: This is important! It turns out the accuracy depends on which part of the dataset is being used for training)\n",
    "    X_train, X_test = train_test_split(data_filtered_scaled, test_size=0.20)\n",
    "\n",
    "    # Instantiate the autoencoder\n",
    "    autoencoder = SimpleAutoencoder(input_size, hidden_size, learning_rate=0.003)\n",
    "\n",
    "    # Train the model\n",
    "    losses = train_autoencoder(X_train, autoencoder, epochs=10000)\n",
    "\n",
    "    # Test accuracy\n",
    "    anomaly_detection_accuracy = check_dropout_prediction_accuracy(X_test, autoencoder)\n",
    "\n",
    "    if anomaly_detection_accuracy > 0.93:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
